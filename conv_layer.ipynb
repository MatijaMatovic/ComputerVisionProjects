{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rM4feoGLJRKO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.random.normal(size=(3, 3, 2))\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fECtuARJXeha",
        "outputId": "13a9d4fb-703a-4d4c-fe8f-089ab4871ebf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[-0.28563073, -0.16043339],\n",
              "        [-0.74400044,  1.09532693],\n",
              "        [-0.31780663, -1.89730885]],\n",
              "\n",
              "       [[-0.1571318 , -1.23555716],\n",
              "        [-0.63246621,  0.63302541],\n",
              "        [-0.2513021 , -0.26742342]],\n",
              "\n",
              "       [[ 0.86617707, -0.21632862],\n",
              "        [ 0.55248821, -1.58236407],\n",
              "        [-0.06013818, -0.79852044]]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvKernel:  # or filter\n",
        "  def __init__(self, kernel_dim: int | tuple[int, int], depth=1, stride: int = 1):\n",
        "    # depth or n_channels\n",
        "    self.kernel_dim = (kernel_dim, kernel_dim, 1) if type(kernel_dim) is int else (*kernel_dim, depth)\n",
        "    self.stride = stride\n",
        "    self.kernel = np.random.normal(size=(kernel_dim))\n",
        "    self.bias = np.random.normal() + 0.5\n",
        "\n",
        "  @staticmethod\n",
        "  def _reLU(x):\n",
        "    return np.where(x < 0, 0, x)\n",
        "\n",
        "  def __call__(self, input, train=False):\n",
        "    if len(input.shape) == 2:\n",
        "      if self.kernel_dim[2] != 1:\n",
        "        raise Exception(f'Dimensions don\\'t match: {input.shape}, {self.kernel_dim}')\n",
        "      else:\n",
        "        input = np.expand_dims(input, axis=-1)\n",
        "    if len(input.shape) not in [2, 3]:\n",
        "      raise Exception('Incorrect input shape')\n",
        "    if len(input.shape) == 3 and input.shape[2] != self.kernel_dim[2]:\n",
        "      raise Exception(f'Input and kernel depths don\\'t match: {input.shape} vs {self.kernel_dim}')\n",
        "\n",
        "    # Original formula is FLOOR((N + 2P - F) / S + 1), but input is already padded in the ConvLayer, so no need to worry about that here\n",
        "    row_convolutions = np.floor((input.shape[0] - self.kernel_dim[0]) / self.stride + 1).astype(int)\n",
        "    col_convolutions = np.floor((input.shape[1] - self.kernel_dim[1]) / self.stride + 1).astype(int)\n",
        "    z = np.zeros((row_convolutions, col_convolutions))\n",
        "    for i in range(0, row_convolutions):\n",
        "      row_start = i * self.stride\n",
        "      row_end = row_start + self.kernel_dim[0]\n",
        "      for j in range(0, col_convolutions):\n",
        "        col_start = j * self.stride\n",
        "        col_end = col_start + self.kernel_dim[1]\n",
        "        z_i = np.sum(input[row_start:row_end, col_start:col_end,:] * self.kernel) + self.bias\n",
        "        z[i,j] = z_i\n",
        "\n",
        "    a = ConvKernel._reLU(z)\n",
        "\n",
        "    if train:\n",
        "      cache = [input, self.kernel, self.bias, self.stride]\n",
        "      return a, cache\n",
        "\n",
        "    return a\n"
      ],
      "metadata": {
        "id": "0Zsi8gchJb2g"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = ConvKernel((2,2), 2)\n",
        "k(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byce9uD-Xnr9",
        "outputId": "72b9c192-60dc-40dc-f8d6-6e01d6dc4e04"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.44296051, 1.39042991],\n",
              "       [3.91765131, 3.09709761]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvLayer:\n",
        "  def __init__(self, kernel_dim: tuple[int, int] | tuple[int, int, int], num_kernels=1, stride=1, padding='valid'):\n",
        "    self.kernel_dim = kernel_dim\n",
        "    self.num_kernels = num_kernels\n",
        "    self.stride=stride\n",
        "    self.padding=padding\n",
        "    self.kernels = []\n",
        "    self.initialized = False\n",
        "    self.input_dimensions = None\n",
        "    self._padding=None\n",
        "\n",
        "  def initialize(self, input):\n",
        "    self.input_dimensions = input.shape # if len(input.shape) == 2 else input.shape[:-1]\n",
        "\n",
        "    # calculate same padding\n",
        "    # P = ceil(((S-1)*W-S+F)/2), with F = filter size, S = stride, W = input size\n",
        "    if self.padding == 'same':\n",
        "      col_padding = np.ceil(\n",
        "          ((self.stride-1) * self.input_dimensions[1] - self.stride + self.kernel_dim[1]) / 2\n",
        "      ).astype(np.int32)\n",
        "      row_padding = np.ceil(\n",
        "          ((self.stride-1) * self.input_dimensions[0] - self.stride + self.kernel_dim[0]) / 2\n",
        "      ).astype(np.int32)\n",
        "\n",
        "      self._padding = (row_padding, col_padding)\n",
        "\n",
        "      self.kernels = [\n",
        "          ConvKernel(\n",
        "              kernel_dim = self.kernel_dim[:-1],\n",
        "              depth = self.kernel_dim[-1],\n",
        "              stride = self.stride\n",
        "          ) for _ in range(self.num_kernels)\n",
        "      ]\n",
        "\n",
        "\n",
        "  def _pad(self, input):\n",
        "    row_pad = np.zeros((input.shape[0], self._padding[0], input.shape[2]))\n",
        "    col_pad = np.zeros((self._padding[1], input.shape[0] + self._padding[0]*2, input.shape[2]))  # as number of rows will increase after row padding\n",
        "\n",
        "    input = np.hstack((row_pad, input, row_pad))\n",
        "    input = np.vstack((col_pad, input, col_pad))\n",
        "\n",
        "    print(input.shape)\n",
        "\n",
        "    return input\n",
        "\n",
        "  def __call__(self, input, train=False):\n",
        "    if not self.initialized:\n",
        "      self.initialize(input)\n",
        "    input = self._pad(input)\n",
        "\n",
        "    if train:\n",
        "      results = np.array([\n",
        "        kernel(input, train)[0] for kernel in self.kernels\n",
        "      ])\n",
        "      cache = np.array([\n",
        "        kernel(input, train)[1] for kernel in self.kernels\n",
        "      ])\n",
        "    else:\n",
        "      results = np.array([\n",
        "        kernel(input, train) for kernel in self.kernels\n",
        "      ])\n",
        "\n",
        "    output = np.moveaxis(results, 0, -1)\n",
        "\n",
        "    if train:\n",
        "      cache = np.array([*cache, self._padding])\n",
        "      return output, cache\n",
        "    return output\n",
        "\n",
        "  def backward(self, dZ, cache):\n",
        "    (A_prev, W, b, stride, padding) = cache\n",
        "    (m, n_H_prev, n_W_prev, n_C_prev) = a_prev.shape\n",
        "    (f, f, n_C_prev, n_C) = W.shape\n",
        "    (m, n_H, n_W, n_C) = dZ.shape\n",
        "\n",
        "    dA_prev = np.zeros(A_prev.shape)\n",
        "    dW = np.zeros(W.shape)\n",
        "    db = np.zeros(b.shape) # b.shape = [1,1,1,n_C]\n",
        "\n",
        "    A_prev_pad = np.pad(A_prev, (padding[0], padding[0]), (padding[1], padding[1]))\n",
        "    dA_prev_pad = np.pad(dA_prev, (padding[0], padding[0]), (padding[1], padding[1]))\n",
        "\n",
        "    for i in range(m):                       # loop over the training examples\n",
        "\n",
        "        # select ith training example from A_prev_pad and dA_prev_pad\n",
        "        a_prev_pad = A_prev_pad[i]\n",
        "        da_prev_pad = dA_prev_pad[i]\n",
        "\n",
        "        for h in range(n_H):                   # loop over vertical axis of the output volume\n",
        "            for w in range(n_W):               # loop over horizontal axis of the output volume\n",
        "                for c in range(n_C):           # loop over the channels of the output volume\n",
        "\n",
        "                    # Find the corners of the current \"slice\"\n",
        "                    vert_start = stride * h\n",
        "                    vert_end = vert_start + f\n",
        "                    horiz_start = stride * w\n",
        "                    horiz_end = horiz_start + f\n",
        "\n",
        "                    # Use the corners to define the slice from a_prev_pad\n",
        "                    a_slice = a_prev_pad[vert_start:vert_end,horiz_start:horiz_end,:]\n",
        "\n",
        "                    # Update gradients for the window and the filter's parameters using the code formulas given above\n",
        "                    da_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :] += W[:,:,:,c] * dZ[i, h, w, c]\n",
        "                    dW[:,:,:,c] += a_slice * dZ[i, h, w, c]\n",
        "                    db[:,:,:,c] += dZ[i, h, w, c]\n",
        "\n",
        "        # Set the ith training example's dA_prev to the unpadded da_prev_pad (Hint: use X[pad:-pad, pad:-pad, :])\n",
        "        dA_prev[i, :, :, :] = da_prev_pad[padding[0]:-padding[0], padding[1]:-padding[1], :]\n",
        "\n",
        "    return dA_prev, dW, db\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "88Qo1RfKfeGd"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_filters = 3\n",
        "\n",
        "k = ConvLayer((3, 3, 3), num_filters, padding='same')\n",
        "x = np.random.normal(size=(5, 5, 3))\n",
        "a, c = k(x, train=True)\n",
        "print(a.shape)\n",
        "print(c.shape)\n",
        "assert a.shape == (*x.shape[:-1], num_filters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2-CKUxplyHB",
        "outputId": "6e68c448-9a2e-4eea-ff1b-b0879a8e794e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7, 7, 3)\n",
            "(5, 5, 3)\n",
            "(4,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-3c7314465406>:56: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  cache = np.array([\n",
            "<ipython-input-37-3c7314465406>:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  cache = np.array([*cache, self._padding])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MaxPoolLayer:\n",
        "  def __init__(self, kernel_dim: int | tuple[int, int], stride=1):\n",
        "    self.kernel_dim = (kernel_dim, kernel_dim) if type(kernel_dim) is int else kernel_dim\n",
        "    self.stride = stride\n",
        "\n",
        "  def __call__(self, input):\n",
        "    if len(input.shape) != 3:\n",
        "      raise Exception('Input must have dimenshion 3: (rows, cols, layers)')\n",
        "\n",
        "    rows, cols, layers = input.shape\n",
        "    row_convolutions = np.floor((input.shape[0] - self.kernel_dim[0]) / self.stride + 1).astype(int)\n",
        "    col_convolutions = np.floor((input.shape[1] - self.kernel_dim[1]) / self.stride + 1).astype(int)\n",
        "\n",
        "    z = np.zeros((row_convolutions, col_convolutions, layers))\n",
        "    for i in range(layers):\n",
        "      layer = i\n",
        "      for j in range(0, row_convolutions):\n",
        "        row_start = j * self.stride\n",
        "        row_end = row_start + self.kernel_dim[0]\n",
        "        for k in range(0, col_convolutions):\n",
        "          col_start = k * self.stride\n",
        "          col_end = col_start + self.kernel_dim[1]\n",
        "          z_i = np.max(input[row_start:row_end,col_start:col_end,layer])\n",
        "          z[j,k,layer] = z_i\n",
        "\n",
        "    return z"
      ],
      "metadata": {
        "id": "-q5300bXm5gX"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.random.normal(size=(4, 4, 1))\n",
        "print(x)\n",
        "mp = MaxPoolLayer(kernel_dim=2, stride=2)\n",
        "print('--MaxPooled----')\n",
        "print(mp(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_GzlHyIqIp0",
        "outputId": "8576cc8f-0f17-4a3c-964c-625879ff4004"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[ 0.84785968]\n",
            "  [-0.51184513]\n",
            "  [ 0.25802967]\n",
            "  [-0.63142137]]\n",
            "\n",
            " [[ 0.96113609]\n",
            "  [ 0.94982028]\n",
            "  [-0.72973484]\n",
            "  [-1.08607309]]\n",
            "\n",
            " [[ 3.74372918]\n",
            "  [ 0.69988795]\n",
            "  [-0.68262831]\n",
            "  [-1.17995028]]\n",
            "\n",
            " [[ 0.243664  ]\n",
            "  [ 1.32086961]\n",
            "  [-0.17208798]\n",
            "  [-0.29396866]]]\n",
            "--MaxPooled----\n",
            "[[[ 0.96113609]\n",
            "  [ 0.25802967]]\n",
            "\n",
            " [[ 3.74372918]\n",
            "  [-0.17208798]]]\n"
          ]
        }
      ]
    }
  ]
}